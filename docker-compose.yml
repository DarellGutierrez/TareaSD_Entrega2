services:
  zookeeper:
    image: confluentinc/cp-zookeeper:6.2.11
    container_name: zookeeper
    hostname: zookeeper
    ports:
      - "2181:2181"
    networks:
      - appnet
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:6.2.11
    container_name: kafka
    hostname: kafka
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:9092 --list"]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      - zookeeper
    ports:
      - "29092:29092"
      #- "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
    networks:
      - appnet

  # --- INICIO DEL NUEVO SERVICIO ---
  kafka-setup:
    # 1. Usa la misma imagen de kafka
    image: confluentinc/cp-kafka:6.2.11
    container_name: kafka-setup
    depends_on: # 2. depende de que kafka esté saludable
      kafka:
        condition: service_healthy
    networks:
      - appnet
    
    # 3. Este es el comando que se ejecutará
    command: >
      bash -c '
        echo "Esperando a que Kafka esté listo..."
        
        # Bucle de espera: Intenta listar tópicos hasta que funcione
        until kafka-topics --list --bootstrap-server kafka:9092; do
          echo "Esperando a Kafka..."
          sleep 2
        done
        
        echo "Kafka está listo. Creando tópicos..."
        
        # --- AÑADE AQUÍ TODOS TUS TÓPICOS ---
        kafka-topics --create --topic preguntas_nuevas --bootstrap-server kafka:9092 --replication-factor 1 --partitions 1
        kafka-topics --create --topic respuestas_exitosas --bootstrap-server kafka:9092 --replication-factor 1 --partitions 1
        kafka-topics --create --topic reintentos_cuota --bootstrap-server kafka:9092 --replication-factor 1 --partitions 1
        kafka-topics --create --topic reintentos_sobrecarga --bootstrap-server kafka:9092 --replication-factor 1 --partitions 1
        kafka-topics --create --topic fallidas_terminales --bootstrap-server kafka:9092 --replication-factor 1 --partitions 1
        
        echo "Tópicos creados exitosamente."
      '
  # --- FIN DEL NUEVO SERVICIO ---

  generador:
    build: ./generador_trafico
    volumes:
      - ./dataset:/app/dataset #vincular el directorio donde se ubica el dataset al directorio /app del contenedor
      - ./generador_trafico:/app #introducir el directorio entero dentro de docker para poder ejecutar el script directamente
      - ./db_manager/db_manager.py:/app/db_manager.py
    depends_on:
      #- cache
      kafka:
        condition: service_healthy
    networks:
      - appnet

#  score:
#    environment: 
#      GOOGLE_API_KEY: tukeydeapidegemini  #colocar key de api de gemini para realizar consultas
#      GEMINI_MODEL: gemini-2.5-flash-lite
#      MOCK_GEMINI: 0  #cambiar a 1 para probar rendimiento de cache, saltándo las consultas a gemini
#    build: ./score
#    ports:
#      - "5000:5000"
#    depends_on:
#      db:
#        condition: service_healthy
#    volumes:
#      - ./dataset:/app/dataset #vincular el directorio donde se ubica el dataset al directorio /app del contenedor
#      - ./db_manager/db_manager.py:/app/db_manager.py
#      - ./score:/app  #para poder acceder al score.py dentro del docker sin actualizar
#    networks:
#      - appnet

  servicio-llm:
    build: ./servicioLLM # Asumiendo que el Dockerfile está aquí
    volumes:
      - ./servicioLLM/:/app/
    networks:
      - appnet
    environment:
      - GOOGLE_API_KEY=AIzaSyB5J_b9KPj1I3NfRzPtTGAPf4fo2Rs-No0 # Pasa la API key
      - GEMINI_MODEL=gemini-2.5-flash-lite
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092 # 'kafka:9092' es el nombre del servicio *dentro* de Docker
    depends_on:
      kafka:
        condition: service_healthy

  # --- Flink ---
  flink-jobmanager:
    image: flink:1.15.4-java11
    container_name: flink-jobmanager
    ports:
      - "8081:8081"
    command: jobmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=flink-jobmanager
    networks:
      - appnet

  flink-taskmanager:
    image: flink:1.15.4-java11
    container_name: flink-taskmanager
    depends_on:
      - flink-jobmanager
    command: taskmanager
    scale: 1 # Puedes escalar el número de task managers
    environment:
      - JOB_MANAGER_RPC_ADDRESS=flink-jobmanager
    networks:
      - appnet

  flink-job-submitter:
    build:
      context: .
      dockerfile: Dockerfile.flink
    container_name: flink-job-submitter
    depends_on:
      flink-jobmanager:
        condition: service_started
      kafka-setup:
          condition: service_completed_successfully
    command: flink run -m flink-jobmanager:8081 -d /opt/flink/usrlib/flink-job.jar
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - DB_HOST=db
      - SCORE_THRESHOLD=0.25 # Umbral de aceptación de respuestas para guardar en la db
      - MAX_QUALITY_RETRIES=3
    networks:
      - appnet

  reintentador-cuota:
    build: ./reintentador_cuota
    networks:
      - appnet
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - RETRY_DELAY_SECONDS=61 # Espera fija antes de reintentar
    depends_on:
      kafka:
        condition: service_healthy

  reintentador-sobrecarga:
    build: ./reintentador_sobrecarga
    networks:
      - appnet
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - INITIAL_BACKOFF_SECONDS=5 # Espera inicial para backoff
      - MAX_RETRIES=4 # Número máximo de reintentos
    depends_on:
      kafka:
        condition: service_healthy

  db:
    image: postgres:latest
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: db_consultas
    ports:
      - "5432:5432"
    volumes:
      - db_data:/var/lib/postgresql/data
      - ./db/init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - appnet
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d db_consultas"]
      interval: 10s
      timeout: 5s
      retries: 5

networks:
  appnet:

volumes:
  db_data: